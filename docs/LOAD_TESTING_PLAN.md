# Plan Mont√©e en Charge - eBook Scene Packer v2

**Date** : 2025-11-03  
**Version** : 1.0.0

---

## üéØ Objectif

D√©finir le plan de mont√©e en charge pour garantir que l'application peut supporter la charge pr√©vue en production.

---

## üìä Objectifs Performance

### Objectifs Actuels

- **Temps r√©ponse API** : < 200ms (p95)
- **Taux erreurs** : < 0.1%
- **Support utilisateurs** : 100 utilisateurs simultan√©s
- **Support donn√©es** : 1000+ releases

### Objectifs Production

- **Temps r√©ponse API** : < 200ms (p95), < 500ms (p99)
- **Taux erreurs** : < 0.1%
- **Support utilisateurs** : 500 utilisateurs simultan√©s
- **Support donn√©es** : 10 000+ releases
- **Disponibilit√©** : 99.9% (uptime)

---

## üß™ Tests de Charge

### Outils

**Recommand√©** : **Locust** (Python) ou **k6** (JavaScript)

**Installation Locust** :

```bash
pip install locust
```

**Installation k6** :

```bash
# Sur Linux
sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
echo "deb https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
sudo apt-get update
sudo apt-get install k6
```

---

## üìã Sc√©narios de Charge

### Sc√©nario 1 : Charge Normale

**Objectif** : Valider fonctionnement sous charge normale

**Param√®tres** :
- **Utilisateurs** : 50 utilisateurs simultan√©s
- **Dur√©e** : 30 minutes
- **Ramp-up** : 10 utilisateurs/seconde

**Sc√©nario** :
1. Login (50%)
2. Dashboard (30%)
3. Liste Releases (40%)
4. Cr√©ation Release (10%)
5. Gestion Rules (20%)

**M√©triques √† Mesurer** :
- Temps r√©ponse par endpoint (p50, p95, p99)
- Taux erreurs
- Utilisation CPU/M√©moire
- Requ√™tes DB/seconde
- Taux cache hit

**Crit√®res de R√©ussite** :
- ‚úÖ Temps r√©ponse < 200ms (p95)
- ‚úÖ Taux erreurs < 0.1%
- ‚úÖ CPU < 80%
- ‚úÖ M√©moire < 80%

---

### Sc√©nario 2 : Charge √âlev√©e

**Objectif** : Valider fonctionnement sous charge √©lev√©e

**Param√®tres** :
- **Utilisateurs** : 200 utilisateurs simultan√©s
- **Dur√©e** : 1 heure
- **Ramp-up** : 20 utilisateurs/seconde

**Sc√©nario** : Identique Sc√©nario 1

**M√©triques √† Mesurer** : Identique Sc√©nario 1

**Crit√®res de R√©ussite** :
- ‚úÖ Temps r√©ponse < 500ms (p95)
- ‚úÖ Taux erreurs < 1%
- ‚úÖ CPU < 90%
- ‚úÖ M√©moire < 90%

---

### Sc√©nario 3 : Charge Maximale

**Objectif** : Identifier limites syst√®me

**Param√®tres** :
- **Utilisateurs** : 500 utilisateurs simultan√©s
- **Dur√©e** : 2 heures
- **Ramp-up** : 50 utilisateurs/seconde

**Sc√©nario** : Identique Sc√©nario 1

**M√©triques √† Mesurer** : Identique Sc√©nario 1 + Points de rupture

**Crit√®res de R√©ussite** :
- Identifier point de rupture
- Identifier bottlenecks
- Plan optimisations

---

### Sc√©nario 4 : Spike Test

**Objectif** : Valider r√©silience face √† pics de charge

**Param√®tres** :
- **Utilisateurs** : 0 ‚Üí 300 ‚Üí 0 (spike)
- **Dur√©e** : 15 minutes
- **Spike** : 100 utilisateurs en 10 secondes

**Sc√©nario** : Identique Sc√©nario 1

**M√©triques √† Mesurer** : Identique Sc√©nario 1 + R√©cup√©ration

**Crit√®res de R√©ussite** :
- ‚úÖ Syst√®me r√©cup√®re apr√®s spike
- ‚úÖ Pas de crash
- ‚úÖ Temps r√©ponse se stabilise

---

## üìù Scripts Tests de Charge

### Locust (Python)

```python
# tests/load/locustfile.py
from locust import HttpUser, task, between

class ApplicationUser(HttpUser):
    wait_time = between(1, 3)
    
    def on_start(self):
        """Login before starting."""
        response = self.client.post("/api/auth/login", json={
            "username": "testuser",
            "password": "password"
        })
        self.token = response.json()["access_token"]
        self.headers = {"Authorization": f"Bearer {self.token}"}
    
    @task(5)
    def view_dashboard(self):
        """View dashboard."""
        self.client.get("/api/dashboard/stats", headers=self.headers)
    
    @task(4)
    def list_releases(self):
        """List releases."""
        self.client.get("/api/releases", headers=self.headers)
    
    @task(2)
    def list_rules(self):
        """List rules."""
        self.client.get("/api/rules", headers=self.headers)
    
    @task(1)
    def create_release(self):
        """Create release."""
        self.client.post("/api/wizard/create", json={
            "group": "TestGroup",
            "release_type": "EBOOK"
        }, headers=self.headers)
```

**Ex√©cution** :

```bash
# Mode web UI
locust -f tests/load/locustfile.py --host=http://localhost:5000

# Mode headless
locust -f tests/load/locustfile.py --host=http://localhost:5000 --headless -u 50 -r 10 -t 30m
```

---

### k6 (JavaScript)

```javascript
// tests/load/load_test.js
import http from 'k6/http';
import { check, sleep } from 'k6';

export const options = {
  stages: [
    { duration: '30s', target: 50 },  // Ramp-up
    { duration: '30m', target: 50 }, // Maintain
    { duration: '30s', target: 0 },  // Ramp-down
  ],
};

let token = '';

export function setup() {
  // Login
  const loginRes = http.post('http://localhost:5000/api/auth/login', JSON.stringify({
    username: 'testuser',
    password: 'password'
  }), {
    headers: { 'Content-Type': 'application/json' },
  });
  
  token = JSON.parse(loginRes.body).access_token;
  return { token };
}

export default function(data) {
  const headers = {
    'Authorization': `Bearer ${data.token}`,
    'Content-Type': 'application/json',
  };
  
  // Dashboard
  const dashboardRes = http.get('http://localhost:5000/api/dashboard/stats', { headers });
  check(dashboardRes, {
    'dashboard status 200': (r) => r.status === 200,
    'dashboard response time < 200ms': (r) => r.timings.duration < 200,
  });
  
  sleep(1);
  
  // List releases
  const releasesRes = http.get('http://localhost:5000/api/releases', { headers });
  check(releasesRes, {
    'releases status 200': (r) => r.status === 200,
    'releases response time < 200ms': (r) => r.timings.duration < 200,
  });
  
  sleep(1);
}
```

**Ex√©cution** :

```bash
k6 run tests/load/load_test.js
```

---

## üöÄ Strat√©gie Scaling

### Horizontal Scaling

**Configuration** :
- **Load Balancer** : Nginx (round-robin)
- **Instances Flask** : 3-5 instances
- **Session Sharing** : Redis (si n√©cessaire)

**Architecture** :

```
Internet
  ‚Üì
Nginx (Load Balancer)
  ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Flask 1 ‚îÇ Flask 2 ‚îÇ Flask 3 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
  ‚Üì
MySQL (Primary + Replica)
```

**Configuration Nginx** :

```nginx
# nginx/nginx.conf
upstream flask_app {
    least_conn;
    server flask1:5000;
    server flask2:5000;
    server flask3:5000;
}

server {
    listen 80;
    server_name example.com;
    
    location / {
        proxy_pass http://flask_app;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

---

### Vertical Scaling

**Optimisations** :

- **Optimisation Requ√™tes DB** :
  - Indexes optimis√©s
  - Requ√™tes optimis√©es (eager loading)
  - Connection pooling

- **Caching Strat√©gique** :
  - Redis pour cache distribu√©
  - Cache endpoints fr√©quents
  - Cache invalidation strat√©gique

- **Optimisation Code** :
  - Code optimis√© (√©viter N+1 queries)
  - Lazy loading frontend
  - Code splitting

---

## üìä M√©triques Production

### M√©triques √† Surveiller

**Backend** :
- Temps r√©ponse API (p50, p95, p99)
- Taux erreurs (4xx, 5xx)
- Requ√™tes DB/seconde
- Taux cache hit
- Utilisation CPU/M√©moire

**Frontend** :
- Temps chargement (First Contentful Paint)
- Temps navigation (Time to Interactive)
- Erreurs JavaScript
- Taille bundle

**Infrastructure** :
- Utilisation CPU/M√©moire serveurs
- Utilisation espace disque
- Bandwidth r√©seau
- Connexions DB

---

## üö® Plan Alertes Production

### Critical

- **Erreurs √©lev√©es** : > 10 erreurs/min pendant 5 min
- **Temps r√©ponse √©lev√©** : p95 > 2s pendant 5 min
- **DB connexion √©chou√©e** : Connexion DB √©choue
- **Espace disque faible** : < 20% espace libre
- **CPU √©lev√©** : > 90% CPU pendant 10 min

### Warning

- **Temps r√©ponse √©lev√©** : p95 > 1s pendant 10 min
- **M√©moire √©lev√©e** : > 85% m√©moire utilis√©e
- **Cache hit rate faible** : < 50% hit rate
- **Requ√™tes DB √©lev√©es** : > 1000 req/s

---

## üìã Checklist Mont√©e en Charge

### Tests
- [ ] Tests charge normaux (50 utilisateurs)
- [ ] Tests charge √©lev√©e (200 utilisateurs)
- [ ] Tests charge maximale (500 utilisateurs)
- [ ] Tests spike (300 utilisateurs spike)
- [ ] Analyse r√©sultats
- [ ] Identification bottlenecks

### Scaling
- [ ] Configuration load balancer (Nginx)
- [ ] Configuration multi-instances Flask
- [ ] Configuration Redis cache distribu√©
- [ ] Configuration MySQL replica

### Monitoring
- [ ] M√©triques production configur√©es
- [ ] Alertes configur√©es
- [ ] Dashboards Grafana cr√©√©s
- [ ] On-call rotation configur√©e

---

## üîó R√©f√©rences

- Locust : https://locust.io/
- k6 : https://k6.io/
- Performance : `docs/PERFORMANCE.md`
- Monitoring : `docs/MONITORING.md`

---

**Derni√®re mise √† jour** : 2025-11-03
